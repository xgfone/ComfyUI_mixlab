import io
import os
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

import numpy as np
import requests
import torch
from PIL import Image
from volcenginesdkarkruntime import Ark
from volcenginesdkarkruntime.types.images.images import SequentialImageGenerationOptions


class SeedreamImageGenerateExecutor:
    """
    A ComfyUI node for generating images using Volcengine Seedream API
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": (
                    "STRING",
                    {"multiline": True, "default": "", "placeholder": "Enter your image generation prompt here..."},
                ),
                "image1": ("IMAGE",),
                "model": (["doubao-seedream-4-0-250828"], {"default": "doubao-seedream-4-0-250828"}),
                "aspect_ratio": (
                    ["1:1", "2:3", "3:2", "4:3", "3:4", "16:9", "9:16", "21:9", "2K", "3K", "3.5K", "4K"],
                    {"default": "1:1"},
                ),
                "sequential_image_generation": (["auto", "enabled", "disabled"], {"default": "auto"}),
                "max_images": ("INT", {"default": 1, "min": 1, "max": 10, "step": 1}),
                "response_format": (["url", "b64_json"], {"default": "url"}),
                "watermark": ("BOOLEAN", {"default": False}),
                "stream": ("BOOLEAN", {"default": False}),
                "base_url": ("STRING", {"default": "https://ark.cn-beijing.volces.com/api/v3"}),
                "use_local_images": ("BOOLEAN", {"default": True, "tooltip": "ä½¿ç”¨æœ¬åœ°å›¾åƒï¼ˆBase64æ ¼å¼ï¼Œå®˜æ–¹æ”¯æŒï¼‰"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 18446744073709551615, "step": 1}),
                "enable_auto_retry": (
                    "BOOLEAN",
                    {"default": True, "tooltip": "å¯ç”¨è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼Œå¤„ç†äº‘ç«¯å·¥ä½œæµçš„å¼‚æ­¥æ‰§è¡Œé—®é¢˜"},
                ),
                "timeout": ("INT", {"default": 70, "min": 10, "max": 300, "step": 1, "tooltip": "æœ€å¤§ç­‰å¾…æ—¶é—´(ç§’)ã€‚"}),
            },
            "optional": {
                # ========= ä»»åŠ¡1é¢å¤–å‚è€ƒå›¾ =========
                "image2": ("IMAGE",),
                "image3": ("IMAGE",),
                "image4": ("IMAGE",),
                "image5": ("IMAGE",),
                # ========= ä»»åŠ¡2 =========
                "prompt2": (
                    "STRING",
                    {"multiline": True, "default": "", "placeholder": "Task 2 promptï¼ˆç•™ç©ºåˆ™ä¸æ‰§è¡Œï¼‰"},
                ),
                "task2_image1": ("IMAGE",),
                "task2_image2": ("IMAGE",),
                "task2_image3": ("IMAGE",),
                # ========= ä»»åŠ¡3 =========
                "prompt3": (
                    "STRING",
                    {"multiline": True, "default": "", "placeholder": "Task 3 promptï¼ˆç•™ç©ºåˆ™ä¸æ‰§è¡Œï¼‰"},
                ),
                "task3_image1": ("IMAGE",),
                "task3_image2": ("IMAGE",),
                "task3_image3": ("IMAGE",),
                # ========= ä»»åŠ¡4 =========
                "prompt4": (
                    "STRING",
                    {"multiline": True, "default": "", "placeholder": "Task 4 promptï¼ˆç•™ç©ºåˆ™ä¸æ‰§è¡Œï¼‰"},
                ),
                "task4_image1": ("IMAGE",),
                "task4_image2": ("IMAGE",),
                "task4_image3": ("IMAGE",),
                # ========= ä»»åŠ¡5 =========
                "prompt5": (
                    "STRING",
                    {"multiline": True, "default": "", "placeholder": "Task 5 promptï¼ˆç•™ç©ºåˆ™ä¸æ‰§è¡Œï¼‰"},
                ),
                "task5_image1": ("IMAGE",),
                "task5_image2": ("IMAGE",),
                "task5_image3": ("IMAGE",),
                # ========= ä»»åŠ¡6 =========
                "prompt6": (
                    "STRING",
                    {"multiline": True, "default": "", "placeholder": "Task 6 promptï¼ˆç•™ç©ºåˆ™ä¸æ‰§è¡Œï¼‰"},
                ),
                "task6_image1": ("IMAGE",),
                "task6_image2": ("IMAGE",),
                "task6_image3": ("IMAGE",),
            },
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "text")
    OUTPUT_IS_LIST = (True, False)
    FUNCTION = "generate_images"
    CATEGORY = "image/generation"

    def __init__(self):
        self.client = None
        self.max_retries = 1
        self.retry_delay = 1.0  # ç§’

    def tensor_to_pil(self, tensor):
        """Convert ComfyUI tensor to PIL Image"""
        # Convert tensor to numpy array
        i = 255.0 * tensor.cpu().numpy()
        img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
        return img

    def pil_to_tensor(self, pil_image):
        """Convert PIL Image to ComfyUI tensor"""
        img = np.array(pil_image).astype(np.float32) / 255.0
        return torch.from_numpy(img)[None,]

    def validate_input_data(self, image1, retry_count=0):
        """
        éªŒè¯è¾“å…¥æ•°æ®çš„å®Œæ•´æ€§ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶å¤„ç†äº‘ç«¯å·¥ä½œæµçš„å¼‚æ­¥ç‰¹æ€§
        """
        max_retries = 1

        # åŸºæœ¬éªŒè¯
        if image1 is None:
            if retry_count < max_retries:
                print(
                    f"è¾“å…¥éªŒè¯å¤±è´¥ (å°è¯• {retry_count + 1}/{max_retries + 1}): image1 ä¸º Noneï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•..."
                )
                time.sleep(self.retry_delay)
                return False, "image1_none"
            else:
                raise ValueError("image1 å‚æ•°æ˜¯å¿…éœ€çš„ï¼Œè¯·ç¡®ä¿ä¸Šæ¸¸èŠ‚ç‚¹å·²æ­£ç¡®è¿æ¥å¹¶æ‰§è¡Œå®Œæˆ")

        # æ£€æŸ¥tensorç±»å‹
        if not isinstance(image1, torch.Tensor):
            if retry_count < max_retries:
                print(
                    f"è¾“å…¥éªŒè¯å¤±è´¥ (å°è¯• {retry_count + 1}/{max_retries + 1}): image1 ç±»å‹é”™è¯¯ {type(image1)}ï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•..."
                )
                time.sleep(self.retry_delay)
                return False, "image1_type"
            else:
                raise ValueError(f"image1 å¿…é¡»æ˜¯torch.Tensorç±»å‹ï¼Œå½“å‰ç±»å‹: {type(image1)}")

        # æ£€æŸ¥tensorå½¢çŠ¶
        if len(image1.shape) < 3:
            if retry_count < max_retries:
                print(
                    f"è¾“å…¥éªŒè¯å¤±è´¥ (å°è¯• {retry_count + 1}/{max_retries + 1}): image1 å½¢çŠ¶æ— æ•ˆ {image1.shape}ï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•..."
                )
                time.sleep(self.retry_delay)
                return False, "image1_shape"
            else:
                raise ValueError(f"image1 tensorå½¢çŠ¶æ— æ•ˆ: {image1.shape}ï¼ŒæœŸæœ›è‡³å°‘3ç»´")

        # æ£€æŸ¥tensoræ•°æ®è´¨é‡ - é¿å…å…¨é›¶æˆ–æ— æ•ˆæ•°æ®
        if torch.all(image1 == 0) or torch.isnan(image1).any():
            if retry_count < max_retries:
                print(
                    f"è¾“å…¥éªŒè¯å¤±è´¥ (å°è¯• {retry_count + 1}/{max_retries + 1}): image1 æ•°æ®è´¨é‡é—®é¢˜ï¼ˆå…¨é›¶æˆ–åŒ…å«NaNï¼‰ï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•..."
                )
                time.sleep(self.retry_delay)
                return False, "image1_quality"
            else:
                print("è­¦å‘Š: image1 åŒ…å«å¼‚å¸¸æ•°æ®ï¼Œä½†å°†ç»§ç»­æ‰§è¡Œ...")

        print(f"âœ… è¾“å…¥éªŒè¯é€šè¿‡: image1 å½¢çŠ¶ {image1.shape}, æ•°æ®ç±»å‹ {image1.dtype}")
        return True, "success"

    def convert_image_to_supported_format(self, pil_image, use_local_images=False):
        """
        å°†æœ¬åœ°å›¾åƒè½¬æ¢ä¸ºAPIæ”¯æŒçš„æ ¼å¼
        æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼šæ”¯æŒBase64ç¼–ç æ ¼å¼ data:image/<å›¾ç‰‡æ ¼å¼>;base64,<Base64ç¼–ç >
        """
        try:
            if use_local_images:
                # ä½¿ç”¨å®˜æ–¹æ”¯æŒçš„Base64æ ¼å¼
                try:
                    import base64

                    # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
                    if pil_image.mode != "RGB":
                        pil_image = pil_image.convert("RGB")

                    # ä¿å­˜ä¸ºPNGæ ¼å¼åˆ°å†…å­˜
                    buffered = io.BytesIO()
                    pil_image.save(buffered, format="PNG")
                    img_bytes = buffered.getvalue()

                    # ç¼–ç ä¸ºBase64
                    img_base64 = base64.b64encode(img_bytes).decode("utf-8")

                    # æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼ï¼šdata:image/png;base64,<base64_image>
                    data_url = f"data:image/png;base64,{img_base64}"

                    return data_url

                except Exception:
                    # è½¬æ¢å¤±è´¥æ—¶å›é€€åˆ°ç¤ºä¾‹å›¾åƒ
                    return self._get_example_image_url()

            # é»˜è®¤æ¨¡å¼ï¼šä½¿ç”¨å®˜æ–¹ç¤ºä¾‹å›¾åƒURL
            return self._get_example_image_url()

        except Exception:
            return self._get_example_image_url()

    def _get_example_image_url(self):
        """è·å–ç¤ºä¾‹å›¾åƒURL"""
        example_urls = [
            "https://ark-project.tos-cn-beijing.volces.com/doc_image/seedream4_imagesToimages_1.png",
            "https://ark-project.tos-cn-beijing.volces.com/doc_image/seedream4_imagesToimages_2.png",
        ]

        import random

        return random.choice(example_urls)

    def aspect_ratio_to_size(self, aspect_ratio):
        """Convert aspect ratio to size parameter"""
        ratio_map = {
            "1:1": "2048x2048",
            "4:3": "2304x1728",
            "3:4": "1728x2304",
            "16:9": "2560x1440",
            "9:16": "1440x2560",
            "3:2": "2496x1664",
            "2:3": "1664x2496",
            # "2:3": "1040x1560",
            "21:9": "3024x1296",
            "2K": "2K",
            "3K": "2133x3200",
            "3.5K": "2933x4400",
            "4K": "4K",
        }
        return ratio_map.get(aspect_ratio, "2048x2048")

    def download_image_from_url(self, url):
        """Download image from URL and convert to tensor"""
        try:
            response = requests.get(url)
            response.raise_for_status()
            image = Image.open(io.BytesIO(response.content))
            if image.mode != "RGB":
                image = image.convert("RGB")
            return self.pil_to_tensor(image)
        except Exception:
            # Return a black placeholder image
            placeholder = Image.new("RGB", (512, 512), color="black")
            return self.pil_to_tensor(placeholder)

    def initialize_client(self, base_url, timeout):
        """Initialize the Ark client"""
        api_key = os.environ.get("ARK_API_KEY")

        if not api_key:
            raise ValueError("API Key is required. Please set ARK_API_KEY environment variable.")

        self.client = Ark(base_url=base_url, api_key=api_key.strip(), timeout=timeout, max_retries=1)

    def generate_images(
        self,
        prompt,
        image1,
        model,
        aspect_ratio,
        sequential_image_generation,
        max_images,
        response_format,
        watermark,
        stream,
        base_url,
        use_local_images,
        seed,
        enable_auto_retry,
        timeout,
        image2=None,
        image3=None,
        image4=None,
        image5=None,
        image6=None,
        prompt2="",
        task2_image1=None,
        task2_image2=None,
        task2_image3=None,
        prompt3="",
        task3_image1=None,
        task3_image2=None,
        task3_image3=None,
        prompt4="",
        task4_image1=None,
        task4_image2=None,
        task4_image3=None,
        prompt5="",
        task5_image1=None,
        task5_image2=None,
        task5_image3=None,
        prompt6="",
        task6_image1=None,
        task6_image2=None,
        task6_image3=None,
    ):
        """
        æ”¯æŒæœ€å¤š 6 ä¸ªä»»åŠ¡çš„å¹¶è¡Œæ‰§è¡Œï¼š
        - ä»»åŠ¡1ï¼šprompt + image1(+image2~image6)
        - ä»»åŠ¡2~6ï¼špromptX + taskX_image1~3
        ä½¿ç”¨ ThreadPoolExecutor å¹¶è¡Œè°ƒç”¨ Seedream æ¥å£ã€‚
        """

        # ========== 1. ç»„è£…ä»»åŠ¡åˆ—è¡¨ ==========
        tasks = []

        # ä»»åŠ¡1ï¼šå¿…è·‘ï¼ˆå› ä¸º image1 / prompt æ˜¯å¿…å¡«ï¼‰
        images = [image1, image2, image3, image4, image5, image6]
        task1_images = [img for img in images if img is not None and img.shape[1] >= 14]
        tasks.append(
            {
                "index": 1,
                "prompt": prompt,
                "images": task1_images,
            }
        )

        # ä»»åŠ¡2~6ï¼šå¦‚æœ promptX éç©ºä¸”è‡³å°‘æœ‰ä¸€å¼ å›¾ï¼Œå°±åŠ å…¥ä»»åŠ¡
        def add_task_if_valid(idx, p, img1, img2, img3):
            if p is None:
                p = ""
            p = p.strip()
            imgs = [img for img in [img1, img2, img3] if img is not None and img.shape[1] >= 14]
            if p != "" and len(imgs) > 0:
                tasks.append(
                    {
                        "index": idx,
                        "prompt": p,
                        "images": imgs,
                    }
                )

        add_task_if_valid(2, prompt2, task2_image1, task2_image2, task2_image3)
        add_task_if_valid(3, prompt3, task3_image1, task3_image2, task3_image3)
        add_task_if_valid(4, prompt4, task4_image1, task4_image2, task4_image3)
        add_task_if_valid(5, prompt5, task5_image1, task5_image2, task5_image3)
        add_task_if_valid(6, prompt6, task6_image1, task6_image2, task6_image3)

        if not tasks:
            raise ValueError("æ²¡æœ‰å¯æ‰§è¡Œçš„ä»»åŠ¡ï¼Œè¯·è‡³å°‘æä¾›ä»»åŠ¡1çš„ prompt å’Œ image1ã€‚")

        # æ ¹æ®ç”¨æˆ·è®¾ç½®å†³å®šæ˜¯å¦å¯ç”¨ä¸Šå±‚é‡è¯•é€»è¾‘
        max_attempts = self.max_retries + 1 if enable_auto_retry else 1

        # ========== 2. å®šä¹‰å•ä»»åŠ¡æ‰§è¡Œå‡½æ•°ï¼ˆåœ¨çº¿ç¨‹é‡Œè·‘ï¼‰ ==========
        def run_single_task(task):
            t_idx = task["index"]
            t_prompt = task["prompt"]
            t_images = task["images"]

            # æœ€å¤šåªå–å‰ 6 å¼ ï¼Œå…¼å®¹ _execute_generation çš„ image1~6 æ¥å£
            t_image1 = t_images[0] if len(t_images) > 0 else None
            t_image2 = t_images[1] if len(t_images) > 1 else None
            t_image3 = t_images[2] if len(t_images) > 2 else None
            t_image4 = t_images[3] if len(t_images) > 3 else None
            t_image5 = t_images[4] if len(t_images) > 4 else None
            t_image6 = t_images[5] if len(t_images) > 5 else None

            last_error = None

            for retry_count in range(max_attempts):
                try:
                    # è¾“å…¥æ ¡éªŒï¼ˆåªå¯¹ image1 åšæ™ºèƒ½éªŒè¯ï¼‰
                    is_valid, error_type = self.validate_input_data(t_image1, retry_count)

                    if not is_valid:
                        if enable_auto_retry and retry_count < self.max_retries:
                            # æœ‰æœºä¼šé‡è¯•
                            continue
                        else:
                            # æœ€ç»ˆå¤±è´¥ï¼ŒæŠ›å‡ºæ ¡éªŒå¼‚å¸¸
                            self.validate_input_data(t_image1, retry_count)

                    if retry_count > 0 and enable_auto_retry:
                        print(f"âœ… ä»»åŠ¡ {t_idx} é‡è¯•æˆåŠŸï¼å¼€å§‹æ‰§è¡Œå›¾åƒç”Ÿæˆ (å°è¯• {retry_count + 1}/{max_attempts})")
                    else:
                        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œå›¾åƒç”Ÿæˆ - ä»»åŠ¡ {t_idx}")

                    # è°ƒç”¨åŸæœ‰å•ä»»åŠ¡çš„æ ¸å¿ƒæ‰§è¡Œé€»è¾‘
                    output_tensors, text_output = self._execute_generation(
                        t_prompt,
                        t_image1,
                        model,
                        aspect_ratio,
                        sequential_image_generation,
                        max_images,
                        response_format,
                        watermark,
                        stream,
                        base_url,
                        use_local_images,
                        seed,
                        enable_auto_retry,
                        timeout,
                        t_image2,
                        t_image3,
                        t_image4,
                        t_image5,
                        t_image6,
                    )

                    return {
                        "index": t_idx,
                        "images": output_tensors,
                        "text": text_output,
                    }

                except Exception as e:
                    last_error = e
                    if enable_auto_retry and retry_count < self.max_retries:
                        print(f"ä»»åŠ¡ {t_idx} æ‰§è¡Œå¤±è´¥ (å°è¯• {retry_count + 1}/{max_attempts}): {str(e)}")
                        print(f"ç­‰å¾… {self.retry_delay} ç§’åé‡è¯•ä»»åŠ¡ {t_idx}...")
                        time.sleep(self.retry_delay)
                        continue
                    else:
                        print(f"ä»»åŠ¡ {t_idx} æœ€ç»ˆå¤±è´¥: {str(e)}")
                        raise e

        # ========== 3. ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ ==========
        all_results = []
        max_workers = min(len(tasks), 6)  # æœ€å¤š 6 ä¸ªå¹¶è¡Œ

        print(f"ğŸ”§ å¹¶è¡Œæ‰§è¡Œ Seedream ä»»åŠ¡æ•°: {len(tasks)} (max_workers={max_workers})")

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_idx = {executor.submit(run_single_task, task): task["index"] for task in tasks}

            for future in as_completed(future_to_idx):
                t_idx = future_to_idx[future]
                try:
                    result = future.result()
                    all_results.append(result)
                except Exception as e:
                    # æŸä¸ªä»»åŠ¡å¼‚å¸¸ï¼Œæ•´ä½“æŠ›å‡ºï¼Œè®© ComfyUI æ˜¾ç¤ºé”™è¯¯
                    raise e

        if not all_results:
            return ([], "âš ï¸ æœªæ‰§è¡Œä»»ä½•ä»»åŠ¡ï¼ˆå¯èƒ½æ‰€æœ‰ä»»åŠ¡éƒ½æ ¡éªŒå¤±è´¥ï¼‰")

        # ========== 4. æŒ‰ä»»åŠ¡é¡ºåºåˆå¹¶è¾“å‡º ==========
        all_results.sort(key=lambda r: r["index"])

        all_output_tensors = []
        all_result_texts = []

        for r in all_results:
            t_idx = r["index"]
            all_output_tensors.extend(r["images"])
            all_result_texts.append(f"===== ä»»åŠ¡ {t_idx} =====\n{r['text']}")

        text_output = "\n\n".join(all_result_texts)

        return (all_output_tensors, text_output)

    def _execute_generation(
        self,
        prompt,
        image1,
        model,
        aspect_ratio,
        sequential_image_generation,
        max_images,
        response_format,
        watermark,
        stream,
        base_url,
        use_local_images,
        seed,
        enable_auto_retry,
        timeout,
        image2=None,
        image3=None,
        image4=None,
        image5=None,
        image6=None,
    ):
        """
        å®é™…æ‰§è¡Œå›¾åƒç”Ÿæˆçš„æ ¸å¿ƒé€»è¾‘
        """
        try:
            # æ ‡å‡†åŒ–seedå‚æ•° - å°†å¤§çš„seedå€¼æ˜ å°„åˆ°æœ‰æ•ˆèŒƒå›´å†…
            normalized_seed = seed
            if seed > 2147483647:
                # ä½¿ç”¨æ¨¡è¿ç®—å°†å¤§seedå€¼æ˜ å°„åˆ°æœ‰æ•ˆèŒƒå›´
                normalized_seed = seed % 2147483647
                print(f"åŸå§‹seedå€¼ {seed} è¢«æ ‡å‡†åŒ–ä¸º {normalized_seed}")

            # Initialize client
            self.initialize_client(base_url, timeout=timeout)

            # Note: normalized_seed parameter is available for workflow tracking but not sent to the API
            # The Volcengine Seedream API doesn't currently support seed parameter

            # Collect input images
            input_images = [image1]
            if image2 is not None:
                input_images.append(image2)
            if image3 is not None:
                input_images.append(image3)
            if image4 is not None:
                input_images.append(image4)
            if image5 is not None:
                input_images.append(image5)
            if image6 is not None:
                input_images.append(image6)

            # Convert input images to URLs
            image_urls = []

            for i, img_tensor in enumerate(input_images):
                # Convert tensor to PIL
                pil_img = self.tensor_to_pil(img_tensor.squeeze(0))
                # è½¬æ¢ä¸ºAPIæ”¯æŒçš„æ ¼å¼
                url = self.convert_image_to_supported_format(pil_img, use_local_images)
                image_urls.append(url)

            if not image_urls:
                # å¦‚æœæ²¡æœ‰å›¾åƒï¼Œä½¿ç”¨é»˜è®¤ç¤ºä¾‹
                image_urls = ["https://bimoai-sh.oss-cn-shanghai.aliyuncs.com/greenscreen/tmpl/0/mask_default.png"]

            # Convert aspect ratio to size
            size = self.aspect_ratio_to_size(aspect_ratio)

            # Prepare generation options
            generation_options = SequentialImageGenerationOptions(max_images=max_images)

            # Generate images
            images_response = self.client.images.generate(
                model=model,
                prompt=prompt,
                image=image_urls,
                size=size,
                sequential_image_generation=sequential_image_generation,
                sequential_image_generation_options=generation_options,
                response_format=response_format,
                watermark=watermark,
                stream=stream,
            )

            # Process generated images and collect information
            output_tensors = []
            result_info = []

            # Collect basic generation info
            result_info.append("ğŸ¨ ç”Ÿæˆä¿¡æ¯:")
            result_info.append(f"ğŸ“ æç¤ºè¯: {prompt}")
            result_info.append(f"ğŸ”§ æ¨¡å‹: {model}")
            result_info.append(f"ğŸ“ å®½é«˜æ¯”: {aspect_ratio}")
            result_info.append(f"ğŸ”„ é¡ºåºç”Ÿæˆ: {sequential_image_generation}")
            result_info.append(f"ğŸ–¼ï¸ ç”Ÿæˆæ•°é‡: {len(images_response.data)}")
            result_info.append(
                f"ğŸ“Š è¾“å…¥å›¾åƒ: {len([img for img in [image1, image2, image3, image4, image5, image6] if img is not None])}"
            )
            result_info.append(f"ğŸ”„ æœ¬åœ°å›¾åƒæ¨¡å¼: {'Base64ç¼–ç ' if use_local_images else 'ç¤ºä¾‹å›¾åƒ'}")
            result_info.append(
                f"ğŸ² ç§å­å€¼: {normalized_seed}" + (f" (åŸå§‹: {seed})" if seed != normalized_seed else "")
            )
            result_info.append(f"âš¡ æ‰§è¡ŒçŠ¶æ€: æˆåŠŸ (è‡ªåŠ¨é‡è¯•: {'å¯ç”¨' if enable_auto_retry else 'ç¦ç”¨'})")
            result_info.append("")

            for i, image_data in enumerate(images_response.data):
                result_info.append(f"ğŸ“· å›¾åƒ {i + 1}:")
                result_info.append(f"   ğŸ”— URL: {image_data.url}")
                result_info.append(f"   ğŸ“ å°ºå¯¸: {image_data.size}")

                # Add any additional metadata if available
                if hasattr(image_data, "revised_prompt") and image_data.revised_prompt:
                    result_info.append(f"   âœï¸ ä¿®è®¢æç¤ºè¯: {image_data.revised_prompt}")

                if hasattr(image_data, "finish_reason") and image_data.finish_reason:
                    result_info.append(f"   âœ… å®ŒæˆåŸå› : {image_data.finish_reason}")

                if response_format == "url":
                    # Download image from URL
                    tensor = self.download_image_from_url(image_data.url)
                    output_tensors.append(tensor)
                else:  # b64_json
                    # Handle base64 encoded image
                    import base64

                    image_data_b64 = image_data.b64_json
                    image_bytes = base64.b64decode(image_data_b64)
                    image = Image.open(io.BytesIO(image_bytes))
                    if image.mode != "RGB":
                        image = image.convert("RGB")
                    tensor = self.pil_to_tensor(image)
                    output_tensors.append(tensor)

                result_info.append("")

            # Add generation parameters info
            result_info.append("âš™ï¸ ç”Ÿæˆå‚æ•°:")
            result_info.append(f"   ğŸ¯ å“åº”æ ¼å¼: {response_format}")
            result_info.append(f"   ğŸ’§ æ°´å°: {'æ˜¯' if watermark else 'å¦'}")
            result_info.append(f"   ğŸŒŠ æµå¼ä¼ è¾“: {'æ˜¯' if stream else 'å¦'}")
            result_info.append(f"   ğŸŒ APIåœ°å€: {base_url}")

            if not output_tensors:
                # Return a placeholder if no images generated
                placeholder = Image.new("RGB", (512, 512), color="black")
                output_tensors = [self.pil_to_tensor(placeholder)]
                result_info.append("âš ï¸ æœªç”Ÿæˆå›¾åƒï¼Œè¿”å›å ä½ç¬¦")
                result_info.append(images_response.error.message)

            # Join all info into a single text output
            text_output = "\n".join(result_info)

            return (output_tensors, text_output)

        except Exception as e:
            error_msg = str(e)

            # ç¡®ä¿normalized_seedåœ¨é”™è¯¯å¤„ç†æ—¶ä¹Ÿå¯ç”¨
            normalized_seed = seed
            if seed > 2147483647:
                normalized_seed = seed % 2147483647

            # Return a placeholder error image with error text
            error_img = Image.new("RGB", (512, 512), color="red")

            # Create detailed error text output with specific troubleshooting
            error_text_parts = ["âŒ å›¾åƒç”Ÿæˆå¤±è´¥", "", f"ğŸ” é”™è¯¯ä¿¡æ¯: {error_msg}", ""]

            # æ ¹æ®é”™è¯¯ç±»å‹æä¾›å…·ä½“çš„è§£å†³å»ºè®®
            if "image1 å‚æ•°æ˜¯å¿…éœ€çš„" in error_msg:
                error_text_parts.extend(
                    [
                        "ğŸš¨ è¾“å…¥å›¾åƒé—®é¢˜:",
                        "   â€¢ image1 è¾“å…¥æœªè¿æ¥æˆ–ä¸Šæ¸¸èŠ‚ç‚¹æœªæ‰§è¡Œå®Œæˆ",
                        "   â€¢ è¯·ç¡®ä¿LoadImageæˆ–å…¶ä»–å›¾åƒç”ŸæˆèŠ‚ç‚¹å·²æ­£ç¡®è¿æ¥",
                        "   â€¢ å»ºè®®ç­‰å¾…ä¸Šæ¸¸èŠ‚ç‚¹å®Œå…¨æ‰§è¡Œåå†è¿è¡Œæ­¤èŠ‚ç‚¹",
                        "   â€¢ å¦‚æœä½¿ç”¨APIè°ƒç”¨ï¼Œè¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–èŠ‚ç‚¹æŒ‰æ­£ç¡®é¡ºåºæ‰§è¡Œ",
                        "",
                    ]
                )
            elif "torch.Tensor" in error_msg:
                error_text_parts.extend(
                    [
                        "ğŸš¨ æ•°æ®ç±»å‹é—®é¢˜:",
                        "   â€¢ è¾“å…¥çš„image1ä¸æ˜¯æœ‰æ•ˆçš„å›¾åƒtensor",
                        "   â€¢ è¯·æ£€æŸ¥ä¸Šæ¸¸èŠ‚ç‚¹æ˜¯å¦æ­£ç¡®è¾“å‡ºå›¾åƒæ•°æ®",
                        "   â€¢ ç¡®ä¿è¿æ¥çš„æ˜¯å›¾åƒè¾“å‡ºç«¯å£ï¼Œè€Œä¸æ˜¯å…¶ä»–ç±»å‹çš„è¾“å‡º",
                        "",
                    ]
                )
            elif "Invalid image file" in error_msg:
                error_text_parts.extend(
                    [
                        "ğŸš¨ å›¾åƒæ–‡ä»¶é—®é¢˜:",
                        "   â€¢ ä¸Šæ¸¸LoadImageèŠ‚ç‚¹çš„å›¾åƒæ–‡ä»¶æ— æ•ˆæˆ–ä¸å­˜åœ¨",
                        "   â€¢ å¸¸è§åŸå› :",
                        "     - æ–‡ä»¶è·¯å¾„æ ¼å¼é”™è¯¯ï¼ˆå¦‚ï¼šclient:syai-prod/...ï¼‰",
                        "     - ä¸´æ—¶æ–‡ä»¶è¿˜æœªç”Ÿæˆå®Œæˆ",
                        "     - æ–‡ä»¶æƒé™æˆ–ç½‘ç»œé—®é¢˜",
                        "     - å·¥ä½œæµæ‰§è¡Œé¡ºåºé—®é¢˜",
                        "   â€¢ è§£å†³æ–¹æ¡ˆ:",
                        "     1. æ£€æŸ¥LoadImageèŠ‚ç‚¹çš„è¾“å…¥è·¯å¾„æ˜¯å¦æ­£ç¡®",
                        "     2. ç¡®ä¿ä½¿ç”¨æœ¬åœ°æ–‡ä»¶è·¯å¾„è€ŒéURLæ ¼å¼",
                        "     3. ç­‰å¾…ä¸Šæ¸¸èŠ‚ç‚¹å®Œå…¨æ‰§è¡Œåå†è¿è¡Œ",
                        "     4. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»",
                        "",
                    ]
                )
            elif "API Key" in error_msg:
                error_text_parts.extend(
                    [
                        "ğŸš¨ APIé…ç½®é—®é¢˜:",
                        "   â€¢ ARK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–æ— æ•ˆ",
                        "   â€¢ è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export ARK_API_KEY='your_api_key'",
                        "   â€¢ ç¡®ä¿API Keyæœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿçš„é…é¢",
                        "",
                    ]
                )
            elif "bigger than max" in error_msg and "seed" in error_msg:
                error_text_parts.extend(
                    [
                        "ğŸš¨ Seedå€¼æº¢å‡ºé—®é¢˜:",
                        f"   â€¢ åŸå§‹seedå€¼ {seed} è¶…è¿‡äº†ç³»ç»Ÿæ”¯æŒçš„æœ€å¤§å€¼",
                        f"   â€¢ å·²è‡ªåŠ¨æ ‡å‡†åŒ–ä¸º: {normalized_seed}",
                        "   â€¢ è¿™ä¸ä¼šå½±å“å›¾åƒç”Ÿæˆè´¨é‡ï¼Œåªæ˜¯ç”¨äºå·¥ä½œæµè·Ÿè¸ª",
                        "   â€¢ å»ºè®®ä½¿ç”¨è¾ƒå°çš„seedå€¼ä»¥é¿å…æ­¤è­¦å‘Š",
                        "",
                    ]
                )

            error_text_parts.extend(
                [
                    f"ğŸ“ æç¤ºè¯: {prompt}",
                    f"ğŸ”§ æ¨¡å‹: {model}",
                    f"ğŸ“ å®½é«˜æ¯”: {aspect_ratio}",
                    f"ğŸ”„ é¡ºåºç”Ÿæˆ: {sequential_image_generation}",
                    f"ğŸ–¼ï¸ æœ€å¤§å›¾åƒæ•°: {max_images}",
                    f"ğŸŒ APIåœ°å€: {base_url}",
                    f"ğŸ§ª ä½¿ç”¨æœ¬åœ°å›¾åƒ: {'æ˜¯' if use_local_images else 'å¦'}",
                    f"ğŸ² ç§å­å€¼: {normalized_seed}" + (f" (åŸå§‹: {seed})" if seed != normalized_seed else ""),
                    "",
                    "ğŸ’¡ æ•…éšœæ’é™¤æ­¥éª¤:",
                    "   1. æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹è¿æ¥æ˜¯å¦æ­£ç¡®",
                    "   2. ç¡®ä¿ä¸Šæ¸¸èŠ‚ç‚¹å·²å®Œå…¨æ‰§è¡Œ",
                    "   3. éªŒè¯API Keyå’Œç½‘ç»œè¿æ¥",
                    "   4. æŸ¥çœ‹ComfyUIæ§åˆ¶å°è·å–è¯¦ç»†æ—¥å¿—",
                ]
            )

            error_text = "\n".join(error_text_parts)

            # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯åˆ°æ§åˆ¶å°ä»¥ä¾¿è°ƒè¯•
            print("SeedreamImageGenerate é”™è¯¯è¯¦æƒ…:")
            print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"  é”™è¯¯ä¿¡æ¯: {error_msg}")
            print(f"  image1 ç±»å‹: {type(image1) if 'image1' in locals() else 'undefined'}")
            if "image1" in locals() and image1 is not None:
                print(f"  image1 å½¢çŠ¶: {getattr(image1, 'shape', 'N/A')}")

            return ([self.pil_to_tensor(error_img)], error_text)
