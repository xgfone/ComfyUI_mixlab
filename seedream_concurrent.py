import asyncio
import io
import os
import time

import aiohttp
import numpy as np
import torch
from PIL import Image
from volcenginesdkarkruntime import Ark
from volcenginesdkarkruntime.types.images.images import SequentialImageGenerationOptions


class SeedreamImageGenerateConcurrent:
    """
    A ComfyUI node for generating images using Volcengine Seedream API with Concurrency Support
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": (
                    "STRING",
                    {"multiline": True, "default": "", "placeholder": "Enter your image generation prompt here..."},
                ),
                "image1": ("IMAGE",),
                "model": (["doubao-seedream-4-0-250828"], {"default": "doubao-seedream-4-0-250828"}),
                "aspect_ratio": (
                    ["1:1", "2:3", "3:2", "4:3", "3:4", "16:9", "9:16", "21:9", "2K", "3K", "3.5K", "4K"],
                    {"default": "1:1"},
                ),
                "sequential_image_generation": (["auto", "enabled", "disabled"], {"default": "auto"}),
                # æ–°å¢å¹¶å‘æ§åˆ¶å‚æ•°
                "batch_size": (
                    "INT",
                    {"default": 1, "min": 1, "max": 5, "step": 1, "tooltip": "å¹¶å‘è¯·æ±‚æ•°é‡ï¼ˆåŒæ—¶å‘èµ·å¤šå°‘ä¸ªä»»åŠ¡ï¼‰"},
                ),
                "max_images": (
                    "INT",
                    {
                        "default": 1,
                        "min": 1,
                        "max": 10,
                        "step": 1,
                        "label": "images_per_req",  # UIæ˜¾ç¤ºåç§°
                        "tooltip": "å•æ¬¡è¯·æ±‚ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡ï¼ˆç»„å›¾æ¨¡å¼ï¼‰",
                    },
                ),
                "response_format": (["url", "b64_json"], {"default": "url"}),
                "watermark": ("BOOLEAN", {"default": False}),
                "stream": ("BOOLEAN", {"default": False}),
                "base_url": ("STRING", {"default": "https://ark.cn-beijing.volces.com/api/v3"}),
                "use_local_images": ("BOOLEAN", {"default": True, "tooltip": "ä½¿ç”¨æœ¬åœ°å›¾åƒï¼ˆBase64æ ¼å¼ï¼Œå®˜æ–¹æ”¯æŒï¼‰"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 18446744073709551615, "step": 1}),
                "enable_auto_retry": ("BOOLEAN", {"default": True, "tooltip": "å¯ç”¨è‡ªåŠ¨é‡è¯•æœºåˆ¶"}),
            },
            "optional": {"image2": ("IMAGE",), "image3": ("IMAGE",), "image4": ("IMAGE",), "image5": ("IMAGE",)},
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "text")
    OUTPUT_IS_LIST = (False, False)  # æ”¹å›Falseï¼Œå› ä¸ºæˆ‘ä»¬ä¼šæŠŠæ‰€æœ‰æ‰¹æ¬¡ç»“æœåˆå¹¶æˆä¸€ä¸ªå¤§Batch
    FUNCTION = "generate_images"
    CATEGORY = "image/generation"

    def __init__(self):
        self.client = None
        self.max_retries = 3
        self.retry_delay = 1.0

    def tensor_to_pil(self, tensor):
        i = 255.0 * tensor.cpu().numpy()
        img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
        return img

    def pil_to_tensor(self, pil_image):
        img = np.array(pil_image).astype(np.float32) / 255.0
        return torch.from_numpy(img)[None,]

    def validate_input_data(self, image1, retry_count=0):
        # ... (ä¿æŒåŸæœ‰çš„éªŒè¯é€»è¾‘ä¸å˜) ...
        max_retries = 3
        if image1 is None:
            if retry_count < max_retries:
                print(
                    f"è¾“å…¥éªŒè¯å¤±è´¥ (å°è¯• {retry_count + 1}/{max_retries + 1}): image1 ä¸º Noneï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•..."
                )
                time.sleep(self.retry_delay)
                return False, "image1_none"
            else:
                raise ValueError("image1 å‚æ•°æ˜¯å¿…éœ€çš„")
        if not isinstance(image1, torch.Tensor):
            if retry_count < max_retries:
                time.sleep(self.retry_delay)
                return False, "image1_type"
            else:
                raise ValueError("image1 å¿…é¡»æ˜¯torch.Tensorç±»å‹")
        if len(image1.shape) < 3:
            if retry_count < max_retries:
                time.sleep(self.retry_delay)
                return False, "image1_shape"
            else:
                raise ValueError("image1 tensorå½¢çŠ¶æ— æ•ˆ")
        return True, "success"

    def convert_image_to_supported_format(self, pil_image, use_local_images=False):
        # ... (ä¿æŒåŸæœ‰çš„è½¬æ¢é€»è¾‘ä¸å˜) ...
        try:
            if use_local_images:
                try:
                    import base64

                    if pil_image.mode != "RGB":
                        pil_image = pil_image.convert("RGB")
                    buffered = io.BytesIO()
                    pil_image.save(buffered, format="PNG")
                    img_bytes = buffered.getvalue()
                    img_base64 = base64.b64encode(img_bytes).decode("utf-8")
                    data_url = f"data:image/png;base64,{img_base64}"
                    return data_url
                except Exception:
                    return self._get_example_image_url()
            return self._get_example_image_url()
        except Exception:
            return self._get_example_image_url()

    def _get_example_image_url(self):
        example_urls = [
            "https://ark-project.tos-cn-beijing.volces.com/doc_image/seedream4_imagesToimages_1.png",
            "https://ark-project.tos-cn-beijing.volces.com/doc_image/seedream4_imagesToimages_2.png",
        ]
        import random

        return random.choice(example_urls)

    def aspect_ratio_to_size(self, aspect_ratio):
        ratio_map = {
            "1:1": "2048x2048",
            "4:3": "2304x1728",
            "3:4": "1728x2304",
            "16:9": "2560x1440",
            "9:16": "1440x2560",
            "3:2": "2496x1664",
            "2:3": "1664x2496",
            "21:9": "3024x1296",
            "2K": "2K",
            "3K": "2133x3200",
            "3.5K": "2933x4400",
            "4K": "4K",
        }
        return ratio_map.get(aspect_ratio, "2048x2048")

    # æ–°å¢å¼‚æ­¥ä¸‹è½½å‡½æ•°
    async def _download_image_async(self, session, url):
        try:
            async with session.get(url) as response:
                response.raise_for_status()
                data = await response.read()
                image = Image.open(io.BytesIO(data))
                if image.mode != "RGB":
                    image = image.convert("RGB")
                return self.pil_to_tensor(image)
        except Exception as e:
            print(f"ä¸‹è½½å¤±è´¥: {e}")
            placeholder = Image.new("RGB", (512, 512), color="black")
            return self.pil_to_tensor(placeholder)

    def initialize_client(self, base_url):
        api_key = os.environ.get("ARK_API_KEY")
        if not api_key:
            raise ValueError("API Key is required. Please set ARK_API_KEY environment variable.")
        self.client = Ark(base_url=base_url, api_key=api_key.strip())

    # æ”¹ä¸ºå¼‚æ­¥å…¥å£å‡½æ•°
    async def generate_images(
        self,
        prompt,
        image1,
        model,
        aspect_ratio,
        sequential_image_generation,
        batch_size,
        max_images,
        response_format,
        watermark,
        stream,
        base_url,
        use_local_images,
        seed,
        enable_auto_retry,
        image2=None,
        image3=None,
        image4=None,
        image5=None,
    ):
        # éªŒè¯é€»è¾‘ (ä¿æŒåŒæ­¥)
        max_attempts = self.max_retries + 1 if enable_auto_retry else 1
        validation_passed = False
        for retry_count in range(max_attempts):
            try:
                is_valid, _ = self.validate_input_data(image1, retry_count)
                if is_valid:
                    validation_passed = True
                    break
            except Exception:
                if retry_count == max_attempts - 1:
                    raise
                time.sleep(self.retry_delay)

        if not validation_passed:
            raise ValueError("è¾“å…¥éªŒè¯å¤±è´¥")

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.initialize_client(base_url)

        # å‡†å¤‡è¾“å…¥å›¾åƒ (é¢„å¤„ç†ï¼Œé¿å…åœ¨å¼‚æ­¥å¾ªç¯ä¸­é‡å¤å¤„ç†)
        input_images = [img for img in [image1, image2, image3, image4, image5] if img is not None]
        image_urls = []
        for img_tensor in input_images:
            pil_img = self.tensor_to_pil(img_tensor.squeeze(0))
            url = self.convert_image_to_supported_format(pil_img, use_local_images)
            image_urls.append(url)

        if not image_urls:
            image_urls = ["https://ark-project.tos-cn-beijing.volces.com/doc_image/seedream4_imagesToimages_1.png"]

        size = self.aspect_ratio_to_size(aspect_ratio)
        generation_options = SequentialImageGenerationOptions(max_images=max_images)

        # å®šä¹‰å•ä¸ªä»»åŠ¡çš„å¼‚æ­¥å‡½æ•°
        async def process_single_batch(task_index):
            current_seed = seed + task_index
            # æ˜ å°„ Seed é˜²æ­¢æº¢å‡º
            normalized_seed = current_seed if current_seed <= 2147483647 else current_seed % 2147483647

            task_log = []
            task_tensors = []

            try:
                # ä½¿ç”¨ asyncio.to_thread åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥ SDK è°ƒç”¨ï¼Œé˜²æ­¢é˜»å¡
                # æ³¨æ„ï¼šArk SDK ç›®å‰ä¸æ”¯æŒ seed å‚æ•°ï¼Œä½†æˆ‘ä»¬é€»è¾‘ä¸Šä½¿ç”¨å®ƒæ¥åŒºåˆ†ä»»åŠ¡
                print(f"ğŸš€ å¯åŠ¨ä»»åŠ¡ {task_index + 1}/{batch_size} (Seed: {normalized_seed})")

                loop = asyncio.get_running_loop()
                images_response = await loop.run_in_executor(
                    None,
                    lambda: self.client.images.generate(
                        model=model,
                        prompt=prompt,
                        image=image_urls,
                        size=size,
                        sequential_image_generation=sequential_image_generation,
                        sequential_image_generation_options=generation_options,
                        response_format=response_format,
                        watermark=watermark,
                        stream=stream,
                    ),
                )

                # å¤„ç†ç»“æœ
                task_log.append(f"âœ… ä»»åŠ¡ {task_index + 1} å®Œæˆï¼Œç”Ÿæˆ {len(images_response.data)} å¼ å›¾")

                # å¼‚æ­¥ä¸‹è½½å›¾ç‰‡
                async with aiohttp.ClientSession() as session:
                    if response_format == "url":
                        download_tasks = [
                            self._download_image_async(session, item.url) for item in images_response.data
                        ]
                        task_tensors = await asyncio.gather(*download_tasks)
                    else:
                        # å¤„ç† b64_json
                        import base64

                        for item in images_response.data:
                            image_bytes = base64.b64decode(item.b64_json)
                            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
                            task_tensors.append(self.pil_to_tensor(image))

                return task_tensors, "\n".join(task_log)

            except Exception as e:
                error_msg = f"âŒ ä»»åŠ¡ {task_index + 1} å¤±è´¥: {str(e)}"
                print(error_msg)
                # è¿”å›çº¢è‰²å ä½å›¾
                error_img = self.pil_to_tensor(Image.new("RGB", (512, 512), color="red"))
                return [error_img], error_msg

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        tasks = [process_single_batch(i) for i in range(batch_size)]
        results = await asyncio.gather(*tasks)

        # æ±‡æ€»ç»“æœ
        all_tensors = []
        all_logs = [f"ğŸ“Š å¹¶å‘æŠ¥å‘Š: æ€»ä»»åŠ¡æ•° {batch_size}\n"]

        for tensors, log in results:
            all_tensors.extend(tensors)
            all_logs.append(log)

        # æœ€ç»ˆåˆå¹¶ Tensor
        if not all_tensors:
            final_tensor = self.pil_to_tensor(Image.new("RGB", (512, 512), color="black"))
        else:
            final_tensor = torch.cat(all_tensors, dim=0)

        return (final_tensor, "\n".join(all_logs))
